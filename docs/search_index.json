[["index.html", "Survey Research Datasets and R Preface", " Survey Research Datasets and R Danny Smith 2020-12-01 Preface This book accompanies the “Survey Research Datasets and R” workshop delivered for the 7th Biennial ACSPRI Social Science Methodology Conference. Many thanks to ACSPRI for having us, and to the workshop attendees for participating. The R packages covered in this book are the result of uncountable hours of hard work by the R community, and all are freely available and released under open source licenses. The work we do would not be possible without them! License This work, as a whole, is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Datasets We chose to use a real life survey dataset for demonstration purposes. The majority of examples throughout use data from NORC at the University of Chicago’s 2018 General Society Survey.1 The online data examples use publicly available data from the Tidy Tuesday project, the Australian Bureau of Meteorology and the Queensland Government. A very heartfelt thankyou to the people and organisations advocating for open data release and doing the work to make this data publicly available. About the author Danny Smith is a Senior Data Scientist at the Social Research Centre. Danny has worked as a survey programmer, analyst and data scientist in the survey research industry for 10 years. His main interest and expertise is in research systems architecture, building systems that support automation of data workflows and processes and associated tools. He is an avid R user and supporter of free and open source software. You can find him on GitHub (https://github.com/gorcha/). Smith, Tom W, Peter Marsden, Michael Hout, and Jibum Kim. General Social Surveys, 1972-2014↩︎ "],["introduction.html", "1 Introduction", " 1 Introduction Although R began as a specialist statistical programming language, the R ecosystem has grown wildly over the past few years making it a viable general-purpose research environment across the whole research lifecycle. Survey research datasets come from a diverse range of sources, often containing richer metadata than your average data frame. This workshop provides a practical demonstration of several packages for accessing and working with survey data, associated metadata and official statistics in R. We will demonstrate: Working with external data sources from common statistical packages (SPSS, SAS, Stata, Excel) and their quirks Easily working with categorical data in R with the “labelled” R package Accessing external databases in an R native way using DBI and dbplyr Accessing publicly accessible data in R scripts via the web Resources for accessing official statistics data in R Participants should have a working knowledge of R to follow along with examples, but beginners are also welcome. "],["statistical-file-formats.html", "2 Statistical file formats", " 2 Statistical file formats A common thread in survey research is working with data provided in various external file formats. This chapter provides a brief overview of file loading for common statistical file formats and Excel. "],["spss-sas-and-stata.html", "2.1 SPSS, SAS and Stata", " 2.1 SPSS, SAS and Stata SPSS, SAS and Stata don’t provide public documentation of their file formats, so we rely on a few good eggs reverse engineering the file formats to be able to read these dirrectly into R. The two most used R packages for accessing these datasets are haven and foreign. 2.1.1 haven Haven enables R to read and write various data formats used by other statistical packages by wrapping the fantastic ReadStat C library written by Evan Miller. Haven is part of the tidyverse. — https://haven.tidyverse.org/ Pros Labelled datasets! Good support for recent file formats, and good translation of data types into appropriate R classes. Supports writing as well as reading. Cons For the non-tidyverse fans - deeply embedded in the tidyverse way of doing things. Somewhat stable, but still has the occasional breaking change. Examples The example below reads the GSS dataset in both SPSS and Stata formats. Note the inclusion of the user_na = TRUE for reading SPSS files. By default read_sav() converts user tagged NA values to NA in R - setting user_na = TRUE retains these values. We’ll go into more detail on working with tagged missing values in section 3.1.2. install.packages(&quot;haven&quot;) library(haven) gss &lt;- read_sav(&quot;data/gss/GSS2018.sav&quot;, user_na = TRUE) gss &lt;- read_stata(&quot;data/gss/GSS2018.dta&quot;) 2.1.2 foreign Reading and writing data stored by some versions of ‘Epi Info’, ‘Minitab’, ‘S’, ‘SAS’, ‘SPSS’, ‘Stata’, ‘Systat’, ‘Weka’, and for reading and writing some ‘dBase’ files. — https://cran.r-project.org/package=foreign Pros Extremely stable. Supported and developed by the R Core Team. Supports additional file formats not supported by haven. Cons Splits long character variables into 255 character variables. Inconsistent support for newer file formats (e.g. no support for Stata after version 12). Difficult to use categorical labels without converting to factors. Examples The example below reads the GSS dataset in both SPSS and Stata formats. install.packages(&quot;foreign&quot;) library(foreign) gss &lt;- read.spss(&quot;data/gss/GSS2018.sav&quot;, use.value.labels = FALSE) %&gt;% as_tibble() gss &lt;- read.dta(&quot;data/gss/GSS2018.dta&quot;, convert.factors = FALSE) %&gt;% as_tibble() "],["excel.html", "2.2 Excel", " 2.2 Excel No discussion of survey datasets would be complete without a mention of good old Excel. Our advice is to avoid Excel if possible - Excel files can have strange import issues, particularly with dates and formulas. Where it is necessary to import Excel files there are many choices, but we would recommend these packages: openxlsx - a custom Excel library built in C++ with an R frontend. In our experience this package has the least weird Excel issues, and is fantastic for writing and styling output tables. readxl - Part of the tidyverse. Built on the libxls C library and the RapidXML C++ library. Very fast and reliable, but can do unexpected things when trying to guess column types. Does not support writing Excel workbooks. xlsx - a wrapper for the Apache POI Java library. Apache POI is well maintained, but extremely high memory usage for larger datasets. "],["labelled-data.html", "3 Labelled data", " 3 Labelled data One of the best (and somewhat accidental) innovations of the haven package is the introduction of value labels and other metadata tags that we commonly see when working with other statistical software into R, primarily via the labelled vector. Labelled vectors were created as an R equivalent to categorical-esque types. Originally this was only intended as a pass-through class to get to factors. As the labelled() documentation from haven says: This class provides few methods, as I expect you’ll coerce to a standard R class (e.g. a factor()) soon after importing. It turns out that the labelled class is immensely useful in its own right. Fortunately R lives in the open source world, and the labelled package was created. This provides a set of helper functions for more easily working with labelled datasets, particularly for label editing and manipulation. We’ll be going through some brief examples of working with labels, but for a more detailed general introduction see the Introduction to labelled vignette. The labelled cheat sheet is a fantastic quick function reference. "],["what-is-labelled-data.html", "3.1 What is labelled data?", " 3.1 What is labelled data? 3.1.1 The basics When reading a dataset using haven, variables have labels and other metadata attached as attributes. Standard attributes included regardless of variable type are: A label attribute with the variable label A format.stata, format.spss, or format.sas attribute, depending on the input type, storing the variable format for the specified file type (e.g. \"F1.0\") library(haven) library(labelled) library(dplyr, warn.conflicts = FALSE) gss &lt;- read_sav(&quot;data/gss/GSS2018.sav&quot;, user_na = TRUE) gss_dta &lt;- read_dta(&quot;data/gss/GSS2018.dta&quot;) # A standard numeric variable, with additional attributes class(gss$YEAR) #&gt; [1] &quot;numeric&quot; str(gss$YEAR) #&gt; num [1:2348] 2018 2018 2018 2018 2018 ... #&gt; - attr(*, &quot;label&quot;)= chr &quot;GSS year for this respondent&quot; #&gt; - attr(*, &quot;format.spss&quot;)= chr &quot;F4.0&quot; attributes(gss$YEAR) #&gt; $label #&gt; [1] &quot;GSS year for this respondent&quot; #&gt; #&gt; $format.spss #&gt; [1] &quot;F4.0&quot; class(gss_dta$year) #&gt; [1] &quot;numeric&quot; str(gss_dta$year) #&gt; num [1:2348] 2018 2018 2018 2018 2018 ... #&gt; - attr(*, &quot;label&quot;)= chr &quot;gss year for this respondent &quot; #&gt; - attr(*, &quot;format.stata&quot;)= chr &quot;%8.0g&quot; attributes(gss_dta$year) #&gt; $label #&gt; [1] &quot;gss year for this respondent &quot; #&gt; #&gt; $format.stata #&gt; [1] &quot;%8.0g&quot; If a variable contains labelled values it will be imported as a haven_labelled vector, which stores the variable labels in the labels attribute. If we’re reading an SPSS file and the variable contains user-defined missing values it will be imported as a haven_labelled_spss vector. This is an extension of the haven_labelled class that also records user-defined missing values in the na_values or na_range attribute as appropriate. # A &quot;labelled&quot; categorical variable class(gss$HEALTH) #&gt; [1] &quot;haven_labelled_spss&quot; &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; #&gt; [4] &quot;double&quot; str(gss$HEALTH) #&gt; dbl+lbl [1:2348] 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 1, 0, 4, 1, 0, 2, 0, 1, 1, ... #&gt; @ label : chr &quot;Condition of health&quot; #&gt; @ na_values : num [1:3] 0 8 9 #&gt; @ format.spss: chr &quot;F1.0&quot; #&gt; @ labels : Named num [1:7] 0 1 2 3 4 8 9 #&gt; ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;IAP&quot; &quot;EXCELLENT&quot; &quot;GOOD&quot; &quot;FAIR&quot; ... attributes(gss$HEALTH) #&gt; $label #&gt; [1] &quot;Condition of health&quot; #&gt; #&gt; $na_values #&gt; [1] 0 8 9 #&gt; #&gt; $class #&gt; [1] &quot;haven_labelled_spss&quot; &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; #&gt; [4] &quot;double&quot; #&gt; #&gt; $format.spss #&gt; [1] &quot;F1.0&quot; #&gt; #&gt; $labels #&gt; IAP EXCELLENT GOOD FAIR POOR DK NA #&gt; 0 1 2 3 4 8 9 class(gss_dta$health) #&gt; [1] &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; &quot;double&quot; str(gss_dta$health) #&gt; dbl+lbl [1:2348] 2, 1, NA(i), NA(i), 1, 2, 2, 1, N... #&gt; @ label : chr &quot;condition of health&quot; #&gt; @ format.stata: chr &quot;%8.0g&quot; #&gt; @ labels : Named num [1:7] 1 2 3 4 NA NA NA #&gt; ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;excellent&quot; &quot;good&quot; &quot;fair&quot; &quot;poor&quot; ... attributes(gss_dta$health) #&gt; $label #&gt; [1] &quot;condition of health&quot; #&gt; #&gt; $format.stata #&gt; [1] &quot;%8.0g&quot; #&gt; #&gt; $class #&gt; [1] &quot;haven_labelled&quot; &quot;vctrs_vctr&quot; &quot;double&quot; #&gt; #&gt; $labels #&gt; excellent good fair poor DK IAP NA #&gt; 1 2 3 4 NA NA NA One immediate advantage of labelled vectors is that value labels are used in data frame printing when using tibble (and by extension the wider tidyverse) and other packages using the pillar printing methods. # Print helpers gss %&gt;% count(HEALTH) #&gt; # A tibble: 6 x 2 #&gt; HEALTH n #&gt; &lt;dbl+lbl&gt; &lt;int&gt; #&gt; 1 0 (NA) [IAP] 774 #&gt; 2 1 [EXCELLENT] 359 #&gt; 3 2 [GOOD] 771 #&gt; 4 3 [FAIR] 355 #&gt; 5 4 [POOR] 84 #&gt; 6 8 (NA) [DK] 5 gss %&gt;% count(HELPSICK) #&gt; # A tibble: 8 x 2 #&gt; HELPSICK n #&gt; &lt;dbl+lbl&gt; &lt;int&gt; #&gt; 1 0 (NA) [IAP] 785 #&gt; 2 1 [GOVT SHOULD HELP] 528 #&gt; 3 2 306 #&gt; 4 3 [AGREE WITH BOTH] 448 #&gt; 5 4 129 #&gt; 6 5 [PEOPLE HELP SELVES] 117 #&gt; 7 8 (NA) [DK] 33 #&gt; 8 9 (NA) [NA] 2 Using head() on a variable will print a nicely formatted summary of the attached metadata, excluding formats. head(gss$HEALTH) #&gt; &lt;labelled_spss&lt;double&gt;[6]&gt;: Condition of health #&gt; [1] 2 1 0 0 1 2 #&gt; Missing values: 0, 8, 9 #&gt; #&gt; Labels: #&gt; value label #&gt; 0 IAP #&gt; 1 EXCELLENT #&gt; 2 GOOD #&gt; 3 FAIR #&gt; 4 POOR #&gt; 8 DK #&gt; 9 NA head(gss_dta$health) #&gt; &lt;labelled&lt;double&gt;[6]&gt;: condition of health #&gt; [1] 2 1 NA(i) NA(i) 1 2 #&gt; #&gt; Labels: #&gt; value label #&gt; 1 excellent #&gt; 2 good #&gt; 3 fair #&gt; 4 poor #&gt; NA(d) DK #&gt; NA(i) IAP #&gt; NA(n) NA 3.1.2 Missing values 3.1.2.1 User-defined missing values (SPSS) SPSS allows for user-defined missing values, where the user can tag a discrete set or a range of values to be treated as missing. These are relatively simple to deal with in haven, and allow for easy differential treatment of missing values in formatting and recoding methods as we’ll see later. They get a handy (NA) prefix when printed in a tibble and return TRUE from is.na(). # Missing values 0, 8 and 9 head(gss$HEALTH) #&gt; &lt;labelled_spss&lt;double&gt;[6]&gt;: Condition of health #&gt; [1] 2 1 0 0 1 2 #&gt; Missing values: 0, 8, 9 #&gt; #&gt; Labels: #&gt; value label #&gt; 0 IAP #&gt; 1 EXCELLENT #&gt; 2 GOOD #&gt; 3 FAIR #&gt; 4 POOR #&gt; 8 DK #&gt; 9 NA gss %&gt;% count(HEALTH, is.na(HEALTH)) #&gt; # A tibble: 6 x 3 #&gt; HEALTH `is.na(HEALTH)` n #&gt; &lt;dbl+lbl&gt; &lt;lgl&gt; &lt;int&gt; #&gt; 1 0 (NA) [IAP] TRUE 774 #&gt; 2 1 [EXCELLENT] FALSE 359 #&gt; 3 2 [GOOD] FALSE 771 #&gt; 4 3 [FAIR] FALSE 355 #&gt; 5 4 [POOR] FALSE 84 #&gt; 6 8 (NA) [DK] TRUE 5 One gotcha in our experience is that although they return TRUE from is.na() they are not considered equivalent to NA in other contexts. # These are not equivalent! gss %&gt;% count(HEALTH, is.na(HEALTH), HEALTH %in% NA) #&gt; # A tibble: 6 x 4 #&gt; HEALTH `is.na(HEALTH)` `HEALTH %in% NA` n #&gt; &lt;dbl+lbl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;int&gt; #&gt; 1 0 (NA) [IAP] TRUE FALSE 774 #&gt; 2 1 [EXCELLENT] FALSE FALSE 359 #&gt; 3 2 [GOOD] FALSE FALSE 771 #&gt; 4 3 [FAIR] FALSE FALSE 355 #&gt; 5 4 [POOR] FALSE FALSE 84 #&gt; 6 8 (NA) [DK] TRUE FALSE 5 Ranges work similarly to discrete values but will exclude all missing values in the range, as you would expect. # Missing value range 13 - 99, plus discrete value 0 head(gss$RINCOME) #&gt; &lt;labelled_spss&lt;double&gt;[6]&gt;: Respondents income #&gt; [1] 13 0 12 12 0 0 #&gt; Missing values: 0 #&gt; Missing range: [13, 99] #&gt; #&gt; Labels: #&gt; value label #&gt; 0 IAP #&gt; 1 LT $1000 #&gt; 2 $1000 TO 2999 #&gt; 3 $3000 TO 3999 #&gt; 4 $4000 TO 4999 #&gt; 5 $5000 TO 5999 #&gt; 6 $6000 TO 6999 #&gt; 7 $7000 TO 7999 #&gt; 8 $8000 TO 9999 #&gt; 9 $10000 - 14999 #&gt; 10 $15000 - 19999 #&gt; 11 $20000 - 24999 #&gt; 12 $25000 OR MORE #&gt; 13 REFUSED #&gt; 98 DK #&gt; 99 NA gss %&gt;% count(RINCOME, is.na(RINCOME)) #&gt; # A tibble: 15 x 3 #&gt; RINCOME `is.na(RINCOME)` n #&gt; &lt;dbl+lbl&gt; &lt;lgl&gt; &lt;int&gt; #&gt; 1 0 (NA) [IAP] TRUE 899 #&gt; 2 1 [LT $1000] FALSE 33 #&gt; 3 2 [$1000 TO 2999] FALSE 32 #&gt; 4 3 [$3000 TO 3999] FALSE 32 #&gt; 5 4 [$4000 TO 4999] FALSE 21 #&gt; 6 5 [$5000 TO 5999] FALSE 21 #&gt; 7 6 [$6000 TO 6999] FALSE 12 #&gt; 8 7 [$7000 TO 7999] FALSE 18 #&gt; 9 8 [$8000 TO 9999] FALSE 33 #&gt; 10 9 [$10000 - 14999] FALSE 94 #&gt; 11 10 [$15000 - 19999] FALSE 61 #&gt; 12 11 [$20000 - 24999] FALSE 107 #&gt; 13 12 [$25000 OR MORE] FALSE 851 #&gt; 14 13 (NA) [REFUSED] TRUE 108 #&gt; 15 98 (NA) [DK] TRUE 26 3.1.2.2 Tagged missing values (SAS, Stata) SAS and Stata take the opposite approach to SPSS - rather than tagging a value as missing, they tag missing data with a “type”. This is also supported by haven, albeit in a slightly different way. Tagged missing values appear in the label set as an NA with an attached letter flagging the type. head(gss_dta$health) #&gt; &lt;labelled&lt;double&gt;[6]&gt;: condition of health #&gt; [1] 2 1 NA(i) NA(i) 1 2 #&gt; #&gt; Labels: #&gt; value label #&gt; 1 excellent #&gt; 2 good #&gt; 3 fair #&gt; 4 poor #&gt; NA(d) DK #&gt; NA(i) IAP #&gt; NA(n) NA Treatment of tagged missing values can be a bit funny compared to user-defined missing values. Note that, in the example below, doing a straight count for “IAP” does not match the SPSS example and is actually combining the “IAP” and “DK” values. gss_dta %&gt;% count(health, is.na(health)) #&gt; # A tibble: 5 x 3 #&gt; health `is.na(health)` n #&gt; &lt;dbl+lbl&gt; &lt;lgl&gt; &lt;int&gt; #&gt; 1 1 [excellent] FALSE 359 #&gt; 2 2 [good] FALSE 771 #&gt; 3 3 [fair] FALSE 355 #&gt; 4 4 [poor] FALSE 84 #&gt; 5 NA(i) [IAP] TRUE 779 In many circumstances tagged NA values will be grouped together like this, which can be misleading, and need to be treated a bit differently. You can use na_tag() to extract the tagged type of the NA values, or is_tagged_na() to check for values with a particular tag. gss_dta %&gt;% count( health, is.na(health), na_tag(health) ) #&gt; # A tibble: 6 x 4 #&gt; health `is.na(health)` `na_tag(health)` n #&gt; &lt;dbl+lbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 1 [excellent] FALSE &lt;NA&gt; 359 #&gt; 2 2 [good] FALSE &lt;NA&gt; 771 #&gt; 3 3 [fair] FALSE &lt;NA&gt; 355 #&gt; 4 4 [poor] FALSE &lt;NA&gt; 84 #&gt; 5 NA(d) [DK] TRUE d 5 #&gt; 6 NA(i) [IAP] TRUE i 774 gss_dta %&gt;% count( health, na_tag(health), is_tagged_na(health), is_tagged_na(health, &quot;d&quot;) ) #&gt; # A tibble: 6 x 5 #&gt; health `na_tag(health)` `is_tagged_na(heal… `is_tagged_na(healt… n #&gt; &lt;dbl+lbl&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;int&gt; #&gt; 1 1 [excell… &lt;NA&gt; FALSE FALSE 359 #&gt; 2 2 [good] &lt;NA&gt; FALSE FALSE 771 #&gt; 3 3 [fair] &lt;NA&gt; FALSE FALSE 355 #&gt; 4 4 [poor] &lt;NA&gt; FALSE FALSE 84 #&gt; 5 NA(d) [DK] d TRUE TRUE 5 #&gt; 6 NA(i) [IAP] i TRUE FALSE 774 3.1.2.3 Zapping To convert tagged or user-defined missing values to a standard R NA, you can use the zap_missing() function on either a vector or a data frame. gss %&gt;% count(HEALTH, zap_missing(HEALTH)) #&gt; # A tibble: 6 x 3 #&gt; HEALTH `zap_missing(HEALTH)` n #&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;int&gt; #&gt; 1 0 (NA) [IAP] NA 774 #&gt; 2 1 [EXCELLENT] 1 [EXCELLENT] 359 #&gt; 3 2 [GOOD] 2 [GOOD] 771 #&gt; 4 3 [FAIR] 3 [FAIR] 355 #&gt; 5 4 [POOR] 4 [POOR] 84 #&gt; 6 8 (NA) [DK] NA 5 gss_dta %&gt;% count(health, na_tag(health), zap_missing(health)) #&gt; # A tibble: 6 x 4 #&gt; health `na_tag(health)` `zap_missing(health)` n #&gt; &lt;dbl+lbl&gt; &lt;chr&gt; &lt;dbl+lbl&gt; &lt;int&gt; #&gt; 1 1 [excellent] &lt;NA&gt; 1 [excellent] 359 #&gt; 2 2 [good] &lt;NA&gt; 2 [good] 771 #&gt; 3 3 [fair] &lt;NA&gt; 3 [fair] 355 #&gt; 4 4 [poor] &lt;NA&gt; 4 [poor] 84 #&gt; 5 NA(d) [DK] d NA 5 #&gt; 6 NA(i) [IAP] i NA 774 You may recall earlier that we mentioned the user_na = TRUE argument for read_sav(). If you use user_na = FALSE (the default), it will convert user defined missing values to NA on the way in. read_sav(&quot;data/gss/GSS2018.sav&quot;, user_na = TRUE) %&gt;% zap_missing() %&gt;% count(HEALTH) #&gt; # A tibble: 5 x 2 #&gt; HEALTH n #&gt; &lt;dbl+lbl&gt; &lt;int&gt; #&gt; 1 1 [EXCELLENT] 359 #&gt; 2 2 [GOOD] 771 #&gt; 3 3 [FAIR] 355 #&gt; 4 4 [POOR] 84 #&gt; 5 NA 779 read_sav(&quot;data/gss/GSS2018.sav&quot;, user_na = FALSE) %&gt;% count(HEALTH) #&gt; # A tibble: 5 x 2 #&gt; HEALTH n #&gt; &lt;dbl+lbl&gt; &lt;int&gt; #&gt; 1 1 [EXCELLENT] 359 #&gt; 2 2 [GOOD] 771 #&gt; 3 3 [FAIR] 355 #&gt; 4 4 [POOR] 84 #&gt; 5 NA 779 "],["converting-labelled-vectors.html", "3.2 Converting labelled vectors", " 3.2 Converting labelled vectors Labelled datasets are great for accessing metadata in the R console, but many functions need base R data types. 3.2.1 Factors The labelled package has a couple of helper functions for converting labelled vectors to factors and character vectors. The to_factor() function is versatile, and can manipulate labels in various ways on the way to factor levels. The levels argument controls how levels are derived from the value labels. # Convert to factors, using the labels as levels gss %&gt;% count(HEALTH = to_factor(HEALTH)) #&gt; # A tibble: 6 x 2 #&gt; HEALTH n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 IAP 774 #&gt; 2 EXCELLENT 359 #&gt; 3 GOOD 771 #&gt; 4 FAIR 355 #&gt; 5 POOR 84 #&gt; 6 DK 5 # Include the category code in the label gss %&gt;% count(HEALTH = to_factor(HEALTH, levels = &quot;prefixed&quot;)) #&gt; # A tibble: 6 x 2 #&gt; HEALTH n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 [0] IAP 774 #&gt; 2 [1] EXCELLENT 359 #&gt; 3 [2] GOOD 771 #&gt; 4 [3] FAIR 355 #&gt; 5 [4] POOR 84 #&gt; 6 [8] DK 5 # Use the category code instead of the label gss %&gt;% count(HEALTH = to_factor(HEALTH, levels = &quot;values&quot;)) #&gt; # A tibble: 6 x 2 #&gt; HEALTH n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 0 774 #&gt; 2 1 359 #&gt; 3 2 771 #&gt; 4 3 355 #&gt; 5 4 84 #&gt; 6 8 5 User defined missing values can be removed from the levels and converted to NA using user_na_to_na = TRUE. # Remove user-defined NA values gss %&gt;% count(HEALTH = to_factor(HEALTH, user_na_to_na = TRUE)) #&gt; # A tibble: 5 x 2 #&gt; HEALTH n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 EXCELLENT 359 #&gt; 2 GOOD 771 #&gt; 3 FAIR 355 #&gt; 4 POOR 84 #&gt; 5 &lt;NA&gt; 779 Labels that don’t exist in the data can be dropped from the levels using drop_unused_labels = TRUE. # Drop unused labels table(to_factor(gss$HEALTH)) #&gt; #&gt; IAP EXCELLENT GOOD FAIR POOR DK NA #&gt; 774 359 771 355 84 5 0 table(to_factor(gss$HEALTH, drop_unused_labels = TRUE)) #&gt; #&gt; IAP EXCELLENT GOOD FAIR POOR DK #&gt; 774 359 771 355 84 5 Factor Levels can easily be sorted by either value or label using the sort_levels argument. By default, they are sorted by value. # Sort by value levels(to_factor(gss$HEALTH, levels = &quot;prefixed&quot;, sort_levels = &quot;values&quot;)) #&gt; [1] &quot;[0] IAP&quot; &quot;[1] EXCELLENT&quot; &quot;[2] GOOD&quot; &quot;[3] FAIR&quot; #&gt; [5] &quot;[4] POOR&quot; &quot;[8] DK&quot; &quot;[9] NA&quot; # Sort by label levels(to_factor(gss$HEALTH, levels = &quot;prefixed&quot;, sort_levels = &quot;labels&quot;)) #&gt; [1] &quot;[8] DK&quot; &quot;[1] EXCELLENT&quot; &quot;[3] FAIR&quot; &quot;[2] GOOD&quot; #&gt; [5] &quot;[0] IAP&quot; &quot;[9] NA&quot; &quot;[4] POOR&quot; # Sort descending levels(to_factor(gss$HEALTH, levels = &quot;prefixed&quot;, sort_levels = &quot;values&quot;, decreasing = TRUE)) #&gt; [1] &quot;[9] NA&quot; &quot;[8] DK&quot; &quot;[4] POOR&quot; &quot;[3] FAIR&quot; #&gt; [5] &quot;[2] GOOD&quot; &quot;[1] EXCELLENT&quot; &quot;[0] IAP&quot; By default unlabelled values will be included with the value used as the factor level. They can be discarded with no_label_to_na = TRUE. gss %&gt;% count(HELPSICK = to_factor(HELPSICK)) #&gt; # A tibble: 8 x 2 #&gt; HELPSICK n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 IAP 785 #&gt; 2 GOVT SHOULD HELP 528 #&gt; 3 2 306 #&gt; 4 AGREE WITH BOTH 448 #&gt; 5 4 129 #&gt; 6 PEOPLE HELP SELVES 117 #&gt; 7 DK 33 #&gt; 8 NA 2 # Convert unlabelled levels to NA gss %&gt;% count(HELPSICK = to_factor(HELPSICK, nolabel_to_na = TRUE)) #&gt; # A tibble: 7 x 2 #&gt; HELPSICK n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 IAP 785 #&gt; 2 GOVT SHOULD HELP 528 #&gt; 3 AGREE WITH BOTH 448 #&gt; 4 PEOPLE HELP SELVES 117 #&gt; 5 DK 33 #&gt; 6 NA 2 #&gt; 7 &lt;NA&gt; 435 And all labelled vectors in the data frame can be converted to factors in one go. # Convert all labelled vectors to factors to_factor(gss) #&gt; # A tibble: 2,348 x 1,065 #&gt; ABANY ABDEFECT ABFELEGL ABHELP1 ABHELP2 ABHELP3 ABHELP4 ABHLTH ABINSPAY #&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; #&gt; 1 NO YES IAP Yes Yes Yes Yes YES People … #&gt; 2 YES YES It depe… No No No No YES People … #&gt; 3 IAP IAP IAP Yes No Yes Yes IAP People … #&gt; 4 IAP IAP Should Yes Yes Yes Yes IAP People … #&gt; 5 NO YES IAP No No No Yes YES People … #&gt; 6 YES YES Should Yes Yes Yes Yes YES People … #&gt; 7 YES YES It depe… Yes No Yes Yes YES People … #&gt; 8 NO YES IAP Yes No Yes Yes YES No answ… #&gt; 9 IAP IAP It depe… Yes Yes Yes Yes IAP People … #&gt; 10 IAP IAP IAP Yes No No Yes IAP People … #&gt; # … with 2,338 more rows, and 1,056 more variables: ABMEDGOV1 &lt;fct&gt;, #&gt; # ABMEDGOV2 &lt;fct&gt;, ABMELEGL &lt;fct&gt;, ABMORAL &lt;fct&gt;, ABNOMORE &lt;fct&gt;, #&gt; # ABPOOR &lt;fct&gt;, ABPOORW &lt;fct&gt;, ABRAPE &lt;fct&gt;, ABSINGLE &lt;fct&gt;, ABSTATE1 &lt;fct&gt;, #&gt; # ABSTATE2 &lt;fct&gt;, ACQNTSEX &lt;fct&gt;, ACTSSOC &lt;fct&gt;, ADMINCONSENT &lt;fct&gt;, #&gt; # ADULTS &lt;fct&gt;, ADVFRONT &lt;fct&gt;, AFFRMACT &lt;fct&gt;, AFRAIDOF &lt;fct&gt;, #&gt; # AFTERLIF &lt;fct&gt;, AGE &lt;fct&gt;, AGED &lt;fct&gt;, AGEKDBRN &lt;fct&gt;, ANCESTRS &lt;fct&gt;, #&gt; # ARTHRTIS &lt;fct&gt;, ASTROLGY &lt;fct&gt;, ASTROSCI &lt;fct&gt;, ATHEISTS &lt;fct&gt;, #&gt; # ATTEND &lt;fct&gt;, ATTEND12 &lt;fct&gt;, ATTENDMA &lt;fct&gt;, ATTENDPA &lt;fct&gt;, AWAY1 &lt;fct&gt;, #&gt; # AWAY11 &lt;fct&gt;, AWAY2 &lt;fct&gt;, AWAY3 &lt;fct&gt;, AWAY4 &lt;fct&gt;, AWAY5 &lt;fct&gt;, #&gt; # AWAY6 &lt;fct&gt;, AWAY7 &lt;fct&gt;, BABIES &lt;fct&gt;, BACKPAIN &lt;fct&gt;, BALLOT &lt;fct&gt;, #&gt; # BALNEG &lt;fct&gt;, BALPOS &lt;fct&gt;, BEFAIR &lt;fct&gt;, BETRLANG &lt;fct&gt;, BIBLE &lt;fct&gt;, #&gt; # BIGBANG &lt;fct&gt;, BIGBANG1 &lt;fct&gt;, BIGBANG2 &lt;fct&gt;, BIRD &lt;fct&gt;, BIRDB4 &lt;fct&gt;, #&gt; # BORN &lt;fct&gt;, BOYORGRL &lt;fct&gt;, BREAKDWN &lt;fct&gt;, BUDDHSTS &lt;fct&gt;, BUYESOP &lt;fct&gt;, #&gt; # BUYVALUE &lt;fct&gt;, CANTRUST &lt;fct&gt;, CAPPUN &lt;fct&gt;, CAT &lt;fct&gt;, CATB4 &lt;fct&gt;, #&gt; # CHARACTR &lt;fct&gt;, CHEMGEN &lt;fct&gt;, CHILDS &lt;fct&gt;, CHLDIDEL &lt;fct&gt;, #&gt; # CHRISTNS &lt;fct&gt;, CHURHPOW &lt;fct&gt;, CLASS &lt;fct&gt;, CLERGVTE &lt;fct&gt;, #&gt; # CLOSETO1 &lt;fct&gt;, CLOSETO2 &lt;fct&gt;, CLOSETO3 &lt;fct&gt;, CLOSETO4 &lt;fct&gt;, #&gt; # CLOSETO5 &lt;fct&gt;, CNTCTFAM &lt;fct&gt;, CNTCTFRD &lt;fct&gt;, CNTCTKID &lt;fct&gt;, #&gt; # CNTCTPAR &lt;fct&gt;, CNTCTSIB &lt;fct&gt;, CODEG &lt;fct&gt;, CODEN &lt;fct&gt;, COEDUC &lt;fct&gt;, #&gt; # COEVWORK &lt;fct&gt;, COFUND &lt;fct&gt;, COHORT &lt;fct&gt;, COHRS1 &lt;fct&gt;, COHRS2 &lt;fct&gt;, #&gt; # COIND10 &lt;fct&gt;, COISCO08 &lt;fct&gt;, COJew &lt;fct&gt;, COLATH &lt;fct&gt;, COLCOM &lt;fct&gt;, #&gt; # COLDEG1 &lt;fct&gt;, COLHOMO &lt;fct&gt;, COLMIL &lt;fct&gt;, COLMSLM &lt;fct&gt;, COLRAC &lt;fct&gt;, #&gt; # COLSCI &lt;fct&gt;, COLSCINM &lt;fct&gt;, … 3.2.2 Character vectors The to_character() function allows you to convert to a character vector instead of a factor, using the same general conversion arguments as to_factor(). # Convert to a character variable gss %&gt;% count(HEALTH = to_character(HEALTH, levels = &quot;prefixed&quot;)) #&gt; # A tibble: 6 x 2 #&gt; HEALTH n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 [0] IAP 774 #&gt; 2 [1] EXCELLENT 359 #&gt; 3 [2] GOOD 771 #&gt; 4 [3] FAIR 355 #&gt; 5 [4] POOR 84 #&gt; 6 [8] DK 5 # Remove tagged NA values gss %&gt;% count(HEALTH = to_character(HEALTH, user_na_to_na = TRUE)) #&gt; # A tibble: 5 x 2 #&gt; HEALTH n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 EXCELLENT 359 #&gt; 2 FAIR 355 #&gt; 3 GOOD 771 #&gt; 4 POOR 84 #&gt; 5 &lt;NA&gt; 779 "],["exploring-datasets.html", "3.3 Exploring datasets", " 3.3 Exploring datasets The labelled package provides a simple helper function look_for() for finding variables with either variable or value labels matching a search term in your dataset. Some simple examples are included below. For a more detailed rundown of the look_for() function see the vignette. # Find variables with &quot;medical&quot; in the label look_for(gss, &quot;medical&quot;) #&gt; pos variable label col_type values #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 314 HELPSICK Should govt help pay for medical ca… dbl+lbl [0] IAP #&gt; ​ ​ ​ ​ [1] GOVT SHOULD HE… #&gt; ​ ​ ​ ​ [3] AGREE WITH BOTH #&gt; ​ ​ ​ ​ [5] PEOPLE HELP SE… #&gt; ​ ​ ​ ​ [8] DK #&gt; ​ ​ ​ ​ [9] NA #&gt; 390 INTMED Interested in medical discoveries dbl+lbl [0] IAP #&gt; ​ ​ ​ ​ [1] Very interested #&gt; ​ ​ ​ ​ [2] Moderately int… #&gt; ​ ​ ​ ​ [3] Not at all int… #&gt; ​ ​ ​ ​ [8] DONT KNOW #&gt; ​ ​ ​ ​ [9] NA #&gt; 498 MEDDOC X should go to general medical doct… dbl+lbl [0] IAP #&gt; ​ ​ ​ ​ [1] YES #&gt; ​ ​ ​ ​ [2] NO #&gt; ​ ​ ​ ​ [8] DK #&gt; ​ ​ ​ ​ [9] NA # Only provide basic details look_for(gss, &quot;income&quot;, details = FALSE) #&gt; pos variable label #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 15 ABPOOR Low income--cant afford more children #&gt; 16 ABPOORW Wrong for woman to get abortion if low income? #&gt; 130 CONINC Family income in constant dollars #&gt; 136 CONRINC Respondent income in constant dollars #&gt; 209 EQWLTH Should govt reduce income differences #&gt; 252 FINRELA Opinion of family income #&gt; 369 INCGAP Income differentials in usa too big #&gt; 370 INCOM16 R&#39;s family income when 16 yrs old #&gt; 371 INCOME Total family income #&gt; 372 INCOME16 Total family income #&gt; 373 INCUSPOP Estimated income status of housing unit #&gt; 722 REALINC Family income in constant $ #&gt; 723 REALRINC R&#39;s income in constant $ #&gt; 805 RINCBLLS Income alone is enough #&gt; 806 RINCOM16 Respondents income #&gt; 807 RINCOME Respondents income #&gt; 927 TAX R&#39;s federal income tax # Search using a regular expression look_for(gss, &quot;medic(al|ation)&quot;, details = FALSE) #&gt; pos variable label #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 314 HELPSICK Should govt help pay for medical care? #&gt; 390 INTMED Interested in medical discoveries #&gt; 498 MEDDOC X should go to general medical doctor for help #&gt; 532 MUSTMED X should be forced to take prescribed medication by law #&gt; 617 OTCMED X should take non-prescription medication #&gt; 813 RXMED X should take prescription medication # Provide a variable summary as a tibble gss %&gt;% look_for(&quot;medic(al|ation)&quot;) %&gt;% as_tibble() #&gt; # A tibble: 6 x 13 #&gt; pos variable label col_type class type levels value_labels na_values #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;nam&gt; &lt;chr&gt; &lt;name&gt; &lt;named list&gt; &lt;named l&gt; #&gt; 1 314 HELPSICK Shou… dbl+lbl &lt;chr… doub… &lt;NULL&gt; &lt;dbl [6]&gt; &lt;dbl [3]&gt; #&gt; 2 390 INTMED Inte… dbl+lbl &lt;chr… doub… &lt;NULL&gt; &lt;dbl [6]&gt; &lt;dbl [3]&gt; #&gt; 3 498 MEDDOC X sh… dbl+lbl &lt;chr… doub… &lt;NULL&gt; &lt;dbl [5]&gt; &lt;dbl [3]&gt; #&gt; 4 532 MUSTMED X sh… dbl+lbl &lt;chr… doub… &lt;NULL&gt; &lt;dbl [5]&gt; &lt;dbl [3]&gt; #&gt; 5 617 OTCMED X sh… dbl+lbl &lt;chr… doub… &lt;NULL&gt; &lt;dbl [5]&gt; &lt;dbl [3]&gt; #&gt; 6 813 RXMED X sh… dbl+lbl &lt;chr… doub… &lt;NULL&gt; &lt;dbl [5]&gt; &lt;dbl [3]&gt; #&gt; # … with 4 more variables: na_range &lt;named list&gt;, unique_values &lt;int&gt;, #&gt; # n_na &lt;int&gt;, range &lt;named list&gt; # Provide a variable summary as a tibble with one row per value gss %&gt;% look_for(&quot;medic(al|ation)&quot;) %&gt;% lookfor_to_long_format() #&gt; # A tibble: 32 x 13 #&gt; pos variable label col_type class type levels value_labels na_values #&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;nam&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;named l&gt; #&gt; 1 314 HELPSICK Shou… dbl+lbl &lt;chr… doub… &lt;NA&gt; [0] IAP &lt;dbl [3]&gt; #&gt; 2 314 HELPSICK Shou… dbl+lbl &lt;chr… doub… &lt;NA&gt; [1] GOVT SH… &lt;dbl [3]&gt; #&gt; 3 314 HELPSICK Shou… dbl+lbl &lt;chr… doub… &lt;NA&gt; [3] AGREE W… &lt;dbl [3]&gt; #&gt; 4 314 HELPSICK Shou… dbl+lbl &lt;chr… doub… &lt;NA&gt; [5] PEOPLE … &lt;dbl [3]&gt; #&gt; 5 314 HELPSICK Shou… dbl+lbl &lt;chr… doub… &lt;NA&gt; [8] DK &lt;dbl [3]&gt; #&gt; 6 314 HELPSICK Shou… dbl+lbl &lt;chr… doub… &lt;NA&gt; [9] NA &lt;dbl [3]&gt; #&gt; 7 390 INTMED Inte… dbl+lbl &lt;chr… doub… &lt;NA&gt; [0] IAP &lt;dbl [3]&gt; #&gt; 8 390 INTMED Inte… dbl+lbl &lt;chr… doub… &lt;NA&gt; [1] Very in… &lt;dbl [3]&gt; #&gt; 9 390 INTMED Inte… dbl+lbl &lt;chr… doub… &lt;NA&gt; [2] Moderat… &lt;dbl [3]&gt; #&gt; 10 390 INTMED Inte… dbl+lbl &lt;chr… doub… &lt;NA&gt; [3] Not at … &lt;dbl [3]&gt; #&gt; # … with 22 more rows, and 4 more variables: na_range &lt;named list&gt;, #&gt; # unique_values &lt;int&gt;, n_na &lt;int&gt;, range &lt;named list&gt; "],["labelled-data-in-other-packages.html", "3.4 Labelled data in other packages", " 3.4 Labelled data in other packages Although labelled datasets are relatively new and somewhat of a niche there are a few packages that are starting to leverage the additional metadata provided. 3.4.1 Frequency tables with questionr The questionr package provides a set of convenient helper functions for survey processing tasks. Some of these use label and missing value metadata for display purposes. Among others, the freq() function provides an equivalent to frequency tables produced in SPSS, and the ltabs() function provides a wrapper for stats::xtabs() that uses labels by default library(questionr) freq(gss$HEALTH) #&gt; n % val% #&gt; [0] IAP 774 33.0 NA #&gt; [1] EXCELLENT 359 15.3 22.9 #&gt; [2] GOOD 771 32.8 49.1 #&gt; [3] FAIR 355 15.1 22.6 #&gt; [4] POOR 84 3.6 5.4 #&gt; [8] DK 5 0.2 NA #&gt; [9] NA 0 0.0 0.0 ltabs(~ HELPSICK + HEALTH, gss) #&gt; HEALTH: Condition of health #&gt; HELPSICK: Should govt help pay for medical care? [0] IAP [1] EXCELLENT [2] GOOD #&gt; [0] IAP 0 177 391 #&gt; [1] GOVT SHOULD HELP 250 52 132 #&gt; [2] 2 138 44 79 #&gt; [3] AGREE WITH BOTH 242 56 101 #&gt; [4] 4 62 17 34 #&gt; [5] PEOPLE HELP SELVES 63 9 28 #&gt; [8] DK 19 4 6 #&gt; [9] NA 0 0 0 #&gt; HEALTH: Condition of health #&gt; HELPSICK: Should govt help pay for medical care? [3] FAIR [4] POOR [8] DK #&gt; [0] IAP 171 45 1 #&gt; [1] GOVT SHOULD HELP 73 20 1 #&gt; [2] 2 40 5 0 #&gt; [3] AGREE WITH BOTH 44 3 2 #&gt; [4] 4 12 4 0 #&gt; [5] PEOPLE HELP SELVES 10 7 0 #&gt; [8] DK 3 0 1 #&gt; [9] NA 2 0 0 #&gt; HEALTH: Condition of health #&gt; HELPSICK: Should govt help pay for medical care? [9] NA #&gt; [0] IAP 0 #&gt; [1] GOVT SHOULD HELP 0 #&gt; [2] 2 0 #&gt; [3] AGREE WITH BOTH 0 #&gt; [4] 4 0 #&gt; [5] PEOPLE HELP SELVES 0 #&gt; [8] DK 0 #&gt; [9] NA 0 3.4.2 Tabling with gtsummary gtsummary was originally developed as a complement to the [gt]{https://gt.rstudio.com/} table presentation package, for easily producing summary tables of common indicators for datasets, regression models and so on. Variable labels will be used for labelling tables by default, where they exist. Value labels are not used by default, but can easily be included by converting the variables to factors as demonstrated in the previous section. library(gtsummary) gss %&gt;% select(HEALTH, HELPSICK, HELPPOOR) %&gt;% to_factor(drop_unused_labels = TRUE, user_na_to_na = TRUE) %&gt;% tbl_summary(by = HEALTH) #&gt; 779 observations missing `HEALTH` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `HEALTH` column before passing to `tbl_summary()`. html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #advxuxvukm .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #advxuxvukm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #advxuxvukm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #advxuxvukm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #advxuxvukm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #advxuxvukm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #advxuxvukm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #advxuxvukm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #advxuxvukm .gt_column_spanner_outer:first-child { padding-left: 0; } #advxuxvukm .gt_column_spanner_outer:last-child { padding-right: 0; } #advxuxvukm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #advxuxvukm .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #advxuxvukm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #advxuxvukm .gt_from_md > :first-child { margin-top: 0; } #advxuxvukm .gt_from_md > :last-child { margin-bottom: 0; } #advxuxvukm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #advxuxvukm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #advxuxvukm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #advxuxvukm .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #advxuxvukm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #advxuxvukm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #advxuxvukm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #advxuxvukm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #advxuxvukm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #advxuxvukm .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #advxuxvukm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #advxuxvukm .gt_sourcenote { font-size: 90%; padding: 4px; } #advxuxvukm .gt_left { text-align: left; } #advxuxvukm .gt_center { text-align: center; } #advxuxvukm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #advxuxvukm .gt_font_normal { font-weight: normal; } #advxuxvukm .gt_font_bold { font-weight: bold; } #advxuxvukm .gt_font_italic { font-style: italic; } #advxuxvukm .gt_super { font-size: 65%; } #advxuxvukm .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic EXCELLENT, N = 3591 GOOD, N = 7711 FAIR, N = 3551 POOR, N = 841 Should govt help pay for medical care? GOVT SHOULD HELP 52 (29%) 132 (35%) 73 (41%) 20 (51%) 2 44 (25%) 79 (21%) 40 (22%) 5 (13%) AGREE WITH BOTH 56 (31%) 101 (27%) 44 (25%) 3 (7.7%) 4 17 (9.6%) 34 (9.1%) 12 (6.7%) 4 (10%) PEOPLE HELP SELVES 9 (5.1%) 28 (7.5%) 10 (5.6%) 7 (18%) Unknown 181 397 176 45 Should govt improve standard of living? GOVT ACTION 28 (16%) 67 (18%) 33 (19%) 13 (36%) 2 23 (13%) 58 (16%) 26 (15%) 3 (8.3%) AGREE WITH BOTH 92 (51%) 162 (43%) 83 (47%) 16 (44%) 4 26 (14%) 59 (16%) 16 (9.0%) 2 (5.6%) PEOPLE HELP SELVES 11 (6.1%) 27 (7.2%) 19 (11%) 2 (5.6%) Unknown 179 398 178 48 1 Statistics presented: n (%) gss %&gt;% transmute(RINCOME, REALINC = unclass(REALINC), FINRELA) %&gt;% to_factor(drop_unused_labels = TRUE, user_na_to_na = TRUE) %&gt;% tbl_summary(by = FINRELA, percent = &quot;row&quot;) #&gt; 27 observations missing `FINRELA` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `FINRELA` column before passing to `tbl_summary()`. html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #suuezdgnzo .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #suuezdgnzo .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #suuezdgnzo .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #suuezdgnzo .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #suuezdgnzo .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #suuezdgnzo .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #suuezdgnzo .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #suuezdgnzo .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #suuezdgnzo .gt_column_spanner_outer:first-child { padding-left: 0; } #suuezdgnzo .gt_column_spanner_outer:last-child { padding-right: 0; } #suuezdgnzo .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #suuezdgnzo .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #suuezdgnzo .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #suuezdgnzo .gt_from_md > :first-child { margin-top: 0; } #suuezdgnzo .gt_from_md > :last-child { margin-bottom: 0; } #suuezdgnzo .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #suuezdgnzo .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #suuezdgnzo .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #suuezdgnzo .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #suuezdgnzo .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #suuezdgnzo .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #suuezdgnzo .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #suuezdgnzo .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #suuezdgnzo .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #suuezdgnzo .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #suuezdgnzo .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #suuezdgnzo .gt_sourcenote { font-size: 90%; padding: 4px; } #suuezdgnzo .gt_left { text-align: left; } #suuezdgnzo .gt_center { text-align: center; } #suuezdgnzo .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #suuezdgnzo .gt_font_normal { font-weight: normal; } #suuezdgnzo .gt_font_bold { font-weight: bold; } #suuezdgnzo .gt_font_italic { font-style: italic; } #suuezdgnzo .gt_super { font-size: 65%; } #suuezdgnzo .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic FAR BELOW AVERAGE, N = 1531 BELOW AVERAGE, N = 5971 AVERAGE, N = 1,0421 ABOVE AVERAGE, N = 4761 FAR ABOVE AVERAGE, N = 531 Respondents income LT $1000 1 (3.0%) 17 (52%) 11 (33%) 4 (12%) 0 (0%) $1000 TO 2999 3 (9.4%) 12 (38%) 11 (34%) 6 (19%) 0 (0%) $3000 TO 3999 2 (6.2%) 11 (34%) 14 (44%) 5 (16%) 0 (0%) $4000 TO 4999 0 (0%) 11 (52%) 7 (33%) 3 (14%) 0 (0%) $5000 TO 5999 3 (14%) 10 (48%) 7 (33%) 1 (4.8%) 0 (0%) $6000 TO 6999 1 (8.3%) 3 (25%) 5 (42%) 2 (17%) 1 (8.3%) $7000 TO 7999 3 (17%) 6 (33%) 7 (39%) 2 (11%) 0 (0%) $8000 TO 9999 4 (12%) 11 (33%) 15 (45%) 2 (6.1%) 1 (3.0%) $10000 - 14999 6 (6.4%) 39 (41%) 40 (43%) 8 (8.5%) 1 (1.1%) $15000 - 19999 7 (12%) 25 (42%) 24 (40%) 3 (5.0%) 1 (1.7%) $20000 - 24999 6 (5.7%) 34 (32%) 56 (53%) 10 (9.4%) 0 (0%) $25000 OR MORE 17 (2.0%) 136 (16%) 428 (51%) 248 (29%) 18 (2.1%) Unknown 100 282 417 182 31 Family income in constant $ 7,378 (4,086, 17,025) 12,485 (5,108, 20,430) 24,970 (12,485, 37,455) 49,940 (30,645, 72,640) 119,879 (30,645, 119,879) 1 Statistics presented: n (%); Median (IQR) gss %&gt;% to_factor(drop_unused_labels = TRUE, user_na_to_na = TRUE) %&gt;% tbl_cross(HELPSICK, HEALTH, percent = &quot;row&quot;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #yjbdninfqd .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #yjbdninfqd .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yjbdninfqd .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #yjbdninfqd .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #yjbdninfqd .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yjbdninfqd .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yjbdninfqd .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #yjbdninfqd .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #yjbdninfqd .gt_column_spanner_outer:first-child { padding-left: 0; } #yjbdninfqd .gt_column_spanner_outer:last-child { padding-right: 0; } #yjbdninfqd .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #yjbdninfqd .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #yjbdninfqd .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #yjbdninfqd .gt_from_md > :first-child { margin-top: 0; } #yjbdninfqd .gt_from_md > :last-child { margin-bottom: 0; } #yjbdninfqd .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #yjbdninfqd .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #yjbdninfqd .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yjbdninfqd .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #yjbdninfqd .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yjbdninfqd .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #yjbdninfqd .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #yjbdninfqd .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yjbdninfqd .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yjbdninfqd .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #yjbdninfqd .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yjbdninfqd .gt_sourcenote { font-size: 90%; padding: 4px; } #yjbdninfqd .gt_left { text-align: left; } #yjbdninfqd .gt_center { text-align: center; } #yjbdninfqd .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #yjbdninfqd .gt_font_normal { font-weight: normal; } #yjbdninfqd .gt_font_bold { font-weight: bold; } #yjbdninfqd .gt_font_italic { font-style: italic; } #yjbdninfqd .gt_super { font-size: 65%; } #yjbdninfqd .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic Condition of health Total EXCELLENT GOOD FAIR POOR Unknown Should govt help pay for medical care? GOVT SHOULD HELP 52 (9.8%) 132 (25%) 73 (14%) 20 (3.8%) 251 (48%) 528 (100%) 2 44 (14%) 79 (26%) 40 (13%) 5 (1.6%) 138 (45%) 306 (100%) AGREE WITH BOTH 56 (12%) 101 (23%) 44 (9.8%) 3 (0.7%) 244 (54%) 448 (100%) 4 17 (13%) 34 (26%) 12 (9.3%) 4 (3.1%) 62 (48%) 129 (100%) PEOPLE HELP SELVES 9 (7.7%) 28 (24%) 10 (8.5%) 7 (6.0%) 63 (54%) 117 (100%) Unknown 181 (22%) 397 (48%) 176 (21%) 45 (5.5%) 21 (2.6%) 820 (100%) Total 359 (15%) 771 (33%) 355 (15%) 84 (3.6%) 779 (33%) 2,348 (100%) "],["accessing-databases.html", "4 Accessing databases", " 4 Accessing databases Aside from static datasets, we often need to access data held in various kinds of SQL database in R. Exporting data adds an unnecessary overhead, so it’s usually desirable to read data from the database directly. There are many ways to access databases from R using traditional SQL queries, but we’ll be focusing on using dbplyr, and by extension DBI, which allows us to use database tables with dplyr as if they were a standard data frame. "],["dbi.html", "4.1 DBI", " 4.1 DBI Before going into the details of dbplyr, we should briefly explain the DBI package. This is just an overview - we’ll see a basic example of working with DBI in the next section. DBI is a generic database access package allowing you to perform most common database operations from R. If you’ve used database packages like RODBC the general approach should be familiar. DBI’s big strength is that it can connect to many different database types using “database backends” that are provided by separate R packages. A few examples are: RPostgres for PostgreSQL RMariaDB for MariaDB or MySQL RSQLite for SQLite odbc for databases that you can access via ODBC (commonly used for MS SQL Server) bigrquery for Google BigQuery These backend packages handle the translation of the standard DBI functions (e.g. running queries, creating and updating tables) to lower level interaction with the database, taking account of any differences in the database implementation and removing these from the view of the user. This means that we can use the same set of functions for many backends. If, for example, we moved our database from a PostgreSQL server to MariaDB we could continue to use the same R code while simply changing the connection settings. A full overview of working with database connections is out of the scope of this book. We would recommend the RStudio Databases using R guide and the DBI documentation as a starting point for connecting to your database of choice. "],["dbplyr.html", "4.2 dbplyr", " 4.2 dbplyr dbplyr is an extension package for dplyr that allows us to access database tables as if they were R data frames. This essentially means we can access a database without directly bulding SQL queries in our code, which can make working with database tables much cleaner and easier to follow. There are some simple examples below to give you the gist, but for a more detailed rundown we’d recommend the Introduction to dbplyr vignette. 4.2.1 Accessing the database Since these examples are intended for public consumption we can’t use a “real” external database. Fortunately, since DBI is a generic frontend we can use any backend for demonstration purposes. First, we’ll create an SQLite database in memory from the gss dataset. Note that this will lose all the label metadata, since SQL tables do not support attributes or extended R classes. If you’re using a different type of database, the dbConnect() call will look a bit different - this function specifies the driver and connection parameters for the database we’re connecting to. gss &lt;- haven::read_sav(&quot;data/gss/GSS2018.sav&quot;, user_na = TRUE) # Connect to a temporary SQLite database in memory con &lt;- DBI::dbConnect(RSQLite::SQLite(), &quot;:memory:&quot;) # Write the gss dataset to a new table &quot;gss&quot; in the database DBI::dbListTables(con) #&gt; character(0) DBI::dbWriteTable(con, &quot;gss&quot;, gss) DBI::dbListTables(con) #&gt; [1] &quot;gss&quot; dplyr allows us to reference a database table as a tibble using the tbl() function. Once we’re connected to a database, it’s simple to create a reference to a SQL table with the tbl() function, using this database connection and the name of the table. Since a DBI connection (our con object) is used in the tbl() function, dplyr knows to use the database functionality provided by dbplyr and DBI to access this data. library(dplyr, warn.conflicts = FALSE) gss_db &lt;- tbl(con, &quot;gss&quot;) gss_db #&gt; # Source: table&lt;gss&gt; [?? x 1,065] #&gt; # Database: sqlite 3.33.0 [:memory:] #&gt; ABANY ABDEFECT ABFELEGL ABHELP1 ABHELP2 ABHELP3 ABHELP4 ABHLTH ABINSPAY #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 1 0 1 1 1 1 1 1 #&gt; 2 1 1 3 2 2 2 2 1 2 #&gt; 3 0 0 0 1 2 1 1 0 2 #&gt; 4 0 0 1 1 1 1 1 0 1 #&gt; 5 2 1 0 2 2 2 1 1 2 #&gt; 6 1 1 1 1 1 1 1 1 1 #&gt; 7 1 1 3 1 2 1 1 1 1 #&gt; 8 2 1 0 1 2 1 1 1 9 #&gt; 9 0 0 3 1 1 1 1 0 1 #&gt; 10 0 0 0 1 2 2 1 0 2 #&gt; # … with more rows, and 1,056 more variables: ABMEDGOV1 &lt;dbl&gt;, ABMEDGOV2 &lt;dbl&gt;, #&gt; # ABMELEGL &lt;dbl&gt;, ABMORAL &lt;dbl&gt;, ABNOMORE &lt;dbl&gt;, ABPOOR &lt;dbl&gt;, ABPOORW &lt;dbl&gt;, #&gt; # ABRAPE &lt;dbl&gt;, ABSINGLE &lt;dbl&gt;, ABSTATE1 &lt;dbl&gt;, ABSTATE2 &lt;dbl&gt;, #&gt; # ACQNTSEX &lt;dbl&gt;, ACTSSOC &lt;dbl&gt;, ADMINCONSENT &lt;dbl&gt;, ADULTS &lt;dbl&gt;, #&gt; # ADVFRONT &lt;dbl&gt;, AFFRMACT &lt;dbl&gt;, AFRAIDOF &lt;dbl&gt;, AFTERLIF &lt;dbl&gt;, AGE &lt;dbl&gt;, #&gt; # AGED &lt;dbl&gt;, AGEKDBRN &lt;dbl&gt;, ANCESTRS &lt;dbl&gt;, ARTHRTIS &lt;dbl&gt;, ASTROLGY &lt;dbl&gt;, #&gt; # ASTROSCI &lt;dbl&gt;, ATHEISTS &lt;dbl&gt;, ATTEND &lt;dbl&gt;, ATTEND12 &lt;dbl&gt;, #&gt; # ATTENDMA &lt;dbl&gt;, ATTENDPA &lt;dbl&gt;, AWAY1 &lt;dbl&gt;, AWAY11 &lt;dbl&gt;, AWAY2 &lt;dbl&gt;, #&gt; # AWAY3 &lt;dbl&gt;, AWAY4 &lt;dbl&gt;, AWAY5 &lt;dbl&gt;, AWAY6 &lt;dbl&gt;, AWAY7 &lt;dbl&gt;, #&gt; # BABIES &lt;dbl&gt;, BACKPAIN &lt;dbl&gt;, BALLOT &lt;dbl&gt;, BALNEG &lt;dbl&gt;, BALPOS &lt;dbl&gt;, #&gt; # BEFAIR &lt;dbl&gt;, BETRLANG &lt;dbl&gt;, BIBLE &lt;dbl&gt;, BIGBANG &lt;dbl&gt;, BIGBANG1 &lt;dbl&gt;, #&gt; # BIGBANG2 &lt;dbl&gt;, BIRD &lt;dbl&gt;, BIRDB4 &lt;dbl&gt;, BORN &lt;dbl&gt;, BOYORGRL &lt;dbl&gt;, #&gt; # BREAKDWN &lt;dbl&gt;, BUDDHSTS &lt;dbl&gt;, BUYESOP &lt;dbl&gt;, BUYVALUE &lt;dbl&gt;, #&gt; # CANTRUST &lt;dbl&gt;, CAPPUN &lt;dbl&gt;, CAT &lt;dbl&gt;, CATB4 &lt;dbl&gt;, CHARACTR &lt;dbl&gt;, #&gt; # CHEMGEN &lt;dbl&gt;, CHILDS &lt;dbl&gt;, CHLDIDEL &lt;dbl&gt;, CHRISTNS &lt;dbl&gt;, #&gt; # CHURHPOW &lt;dbl&gt;, CLASS &lt;dbl&gt;, CLERGVTE &lt;dbl&gt;, CLOSETO1 &lt;dbl&gt;, #&gt; # CLOSETO2 &lt;dbl&gt;, CLOSETO3 &lt;dbl&gt;, CLOSETO4 &lt;dbl&gt;, CLOSETO5 &lt;dbl&gt;, #&gt; # CNTCTFAM &lt;dbl&gt;, CNTCTFRD &lt;dbl&gt;, CNTCTKID &lt;dbl&gt;, CNTCTPAR &lt;dbl&gt;, #&gt; # CNTCTSIB &lt;dbl&gt;, CODEG &lt;dbl&gt;, CODEN &lt;dbl&gt;, COEDUC &lt;dbl&gt;, COEVWORK &lt;dbl&gt;, #&gt; # COFUND &lt;dbl&gt;, COHORT &lt;dbl&gt;, COHRS1 &lt;dbl&gt;, COHRS2 &lt;dbl&gt;, COIND10 &lt;dbl&gt;, #&gt; # COISCO08 &lt;dbl&gt;, COJew &lt;dbl&gt;, COLATH &lt;dbl&gt;, COLCOM &lt;dbl&gt;, COLDEG1 &lt;dbl&gt;, #&gt; # COLHOMO &lt;dbl&gt;, COLMIL &lt;dbl&gt;, COLMSLM &lt;dbl&gt;, COLRAC &lt;dbl&gt;, COLSCI &lt;dbl&gt;, #&gt; # COLSCINM &lt;dbl&gt;, … On first glance gss_db acts and looks like a tibble, but it’s actually quite different. You’ll notice in the example above that the data source is listed in the header, but with an unknown (??) number of rows: # Source: table&lt;gss&gt; [?? x 1,065] # Database: sqlite 3.33.0 [:memory:] The gss_db object is not actually a data frame, but a database connection that pretends to be one. If we look at the class list we’ll see that the original gss dataset is a data frame underneath the tibble, but our database connection is something else. class(gss) #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; class(gss_db) #&gt; [1] &quot;tbl_SQLiteConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; #&gt; [4] &quot;tbl_lazy&quot; &quot;tbl&quot; So although our gss_db object looks like a data frame, it isn’t one. Operations that you can run on a normal data frame won’t necessarily work on a database tibble. table(gss$INCOME) #&gt; #&gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 98 #&gt; 37 28 19 14 14 9 13 42 142 81 140 1444 274 91 table(gss_db$INCOME) #&gt; &lt; table of extent 0 &gt; 4.2.2 Using dplyr verbs Although we can’t use this object exactly like a normal data frame, dplyr is “database aware” via dbplyr. This means that we can use the standard dplyr verbs (select(), mutate(), group_by(), summarise(), etc.) on our gss_db object to perform processing on the SQL table. Instead of immediately processing anything, dplyr builds the operations into a SQL query that will be run on the remote database. We can view the underlying SQL query using show_query(). income &lt;- gss_db %&gt;% group_by(HELPSICK) %&gt;% summarise(REALINC_AVG = mean(REALINC, na.rm = TRUE)) show_query(income) #&gt; &lt;SQL&gt; #&gt; SELECT `HELPSICK`, AVG(`REALINC`) AS `REALINC_AVG` #&gt; FROM `gss` #&gt; GROUP BY `HELPSICK` At this point we still haven’t really done any processing. Similar to the gss_db object, the income object we just created isn’t actually a data frame, but a “lazy query” that stores definitional data prior to processing. When we print the object, it presents a preview of the results. To run the query we call the collect() function, which returns the results as a standard local tibble. # Note that this prints as a &quot;lazy query&quot; income #&gt; # Source: lazy query [?? x 2] #&gt; # Database: sqlite 3.33.0 [:memory:] #&gt; HELPSICK REALINC_AVG #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 30993. #&gt; 2 1 25532. #&gt; 3 2 35434. #&gt; 4 3 32190. #&gt; 5 4 41244. #&gt; 6 5 30856. #&gt; 7 8 17339. #&gt; 8 9 26389. collect(income) #&gt; # A tibble: 8 x 2 #&gt; HELPSICK REALINC_AVG #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 30993. #&gt; 2 1 25532. #&gt; 3 2 35434. #&gt; 4 3 32190. #&gt; 5 4 41244. #&gt; 6 5 30856. #&gt; 7 8 17339. #&gt; 8 9 26389. Not all functions can be translated to SQL, and not all processing can be done using dplyr verbs. By using the collect() function in a pipe we can easily combine remote and local processing in a familiar R native way. This is particularly powerful when working with large datasets that may not be possible to load into memory in R - every operation before the collect() is processed by the SQL database, so operations like selecting, filtering and aggregating can take advantage of the SQL infrastructure. library(tidyr) gss_db %&gt;% group_by(HELPSICK, HEALTH) %&gt;% summarise(N = n()) %&gt;% collect() %&gt;% pivot_wider(names_from = &quot;HEALTH&quot;, names_sort = TRUE, values_from = &quot;N&quot;) #&gt; # A tibble: 8 x 7 #&gt; # Groups: HELPSICK [8] #&gt; HELPSICK `0` `1` `2` `3` `4` `8` #&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 0 NA 177 391 171 45 1 #&gt; 2 1 250 52 132 73 20 1 #&gt; 3 2 138 44 79 40 5 NA #&gt; 4 3 242 56 101 44 3 2 #&gt; 5 4 62 17 34 12 4 NA #&gt; 6 5 63 9 28 10 7 NA #&gt; 7 8 19 4 6 3 NA 1 #&gt; 8 9 NA NA NA 2 NA NA 4.2.3 Disclaimer There’s one big caveat to this approach - it’s not always possible to translate functions to SQL code, and some SQL backends are more robust than others. For simple operations you shouldn’t have any problems, but we highly recommend reading the dbplyr vignettes for a better understanding of how this translation works. Function translation Verb translation If you’re having strange issues preforming certain operations, using the show_query() command to see what dbplyr is actually trying to do is the best first debugging step. "],["online-data.html", "5 Online data", " 5 Online data Accessing data directly from web sources is becoming increasingly common, both from hosted files in more traditional formats and from web APIs. This chapter provides a general overview of accessing online data directly from R, and working with common web API formats. "],["reading-data-directly.html", "5.1 Reading data directly", " 5.1 Reading data directly In the modern R world, a lot of the work of accessing web resources is baked into common data loading packages. Many packages allow you to read directly from a URL as if it were a file on your local machine. The Tidy Tuesday project is a great resource for a varied set of real world examples of loading and working with CSV datasets and spatial data. The code below is taken directly from a Tidy Tuesday Australian Bushfires collection from early 2020. This example reads CSV data directly from web links using readr, and spatial data from JSON using sf. # Get the Data rainfall &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-07/rainfall.csv&#39;) temperature &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-07/temperature.csv&#39;) # IF YOU USE THIS DATA PLEASE BE CAUTIOUS WITH INTERPRETATION nasa_fire &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-07/MODIS_C6_Australia_and_New_Zealand_7d.csv&#39;) # For JSON File of fires url &lt;- &quot;http://www.rfs.nsw.gov.au/feeds/majorIncidents.json&quot; aus_fires &lt;- sf::st_read(url) If you need to load data from a web source, check the help page for your read function and see if it supports reading from URLs as well as local file paths before you dive into anything more complicated. "],["json-data.html", "5.2 JSON data", " 5.2 JSON data Data provided via web APIs is often made available in JSON (JavaScript Object Notation) format, a simple human readable text format for storing hierarchical data. There are a few R packages that parse JSON data, but jsonlite is our package of choice. Like readr and sf, jsonlite can read data directly from a URL. Data for for the following examples is sourced from the Australian Bureau of Meteorology’s Latest Weather Observations for Melbourne Airport, made available directly from their website in JSON format. # Bureau of Meteorology - Latest Weather Observations for Melbourne Airport bom_url &lt;- &quot;http://www.bom.gov.au/fwo/IDV60901/IDV60901.94866.json&quot; bom_data &lt;- jsonlite::fromJSON(bom_url) jsonlite has an intuitive mapping from JSON data types to R. The object returned from the BoM site is a list containing various pieces of metadata alongside our data of interest. Check out the original URL to see the JSON data that has been mapped to this R structure. str(bom_data) #&gt; List of 1 #&gt; $ observations:List of 3 #&gt; ..$ notice:&#39;data.frame&#39;: 1 obs. of 4 variables: #&gt; .. ..$ copyright : chr &quot;Copyright Commonwealth of Australia 2020, Bureau of Meteorology. For more information see: http://www.bom.gov.a&quot;| __truncated__ #&gt; .. ..$ copyright_url : chr &quot;http://www.bom.gov.au/other/copyright.shtml&quot; #&gt; .. ..$ disclaimer_url: chr &quot;http://www.bom.gov.au/other/disclaimer.shtml&quot; #&gt; .. ..$ feedback_url : chr &quot;http://www.bom.gov.au/other/feedback&quot; #&gt; ..$ header:&#39;data.frame&#39;: 1 obs. of 8 variables: #&gt; .. ..$ refresh_message: chr &quot;Issued at 2:11 pm EDT Tuesday 1 December 2020&quot; #&gt; .. ..$ ID : chr &quot;IDV60901&quot; #&gt; .. ..$ main_ID : chr &quot;IDV60900&quot; #&gt; .. ..$ name : chr &quot;Melbourne Airport&quot; #&gt; .. ..$ state_time_zone: chr &quot;VIC&quot; #&gt; .. ..$ time_zone : chr &quot;EDT&quot; #&gt; .. ..$ product_name : chr &quot;Capital City Observations&quot; #&gt; .. ..$ state : chr &quot;Victoria&quot; #&gt; ..$ data :&#39;data.frame&#39;: 161 obs. of 35 variables: #&gt; .. ..$ sort_order : int [1:161] 0 1 2 3 4 5 6 7 8 9 ... #&gt; .. ..$ wmo : int [1:161] 94866 94866 94866 94866 94866 94866 94866 94866 94866 94866 ... #&gt; .. ..$ name : chr [1:161] &quot;Melbourne Airport&quot; &quot;Melbourne Airport&quot; &quot;Melbourne Airport&quot; &quot;Melbourne Airport&quot; ... #&gt; .. ..$ history_product : chr [1:161] &quot;IDV60901&quot; &quot;IDV60901&quot; &quot;IDV60901&quot; &quot;IDV60901&quot; ... #&gt; .. ..$ local_date_time : chr [1:161] &quot;01/02:00pm&quot; &quot;01/01:30pm&quot; &quot;01/01:00pm&quot; &quot;01/12:30pm&quot; ... #&gt; .. ..$ local_date_time_full: chr [1:161] &quot;20201201140000&quot; &quot;20201201133000&quot; &quot;20201201130000&quot; &quot;20201201123000&quot; ... #&gt; .. ..$ aifstime_utc : chr [1:161] &quot;20201201030000&quot; &quot;20201201023000&quot; &quot;20201201020000&quot; &quot;20201201013000&quot; ... #&gt; .. ..$ lat : num [1:161] -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 ... #&gt; .. ..$ lon : num [1:161] 145 145 145 145 145 ... #&gt; .. ..$ apparent_t : num [1:161] 18.8 17.3 15.3 14 14.1 14.2 13.9 15.6 17.5 19.4 ... #&gt; .. ..$ cloud : chr [1:161] &quot;Mostly clear&quot; &quot;Mostly clear&quot; &quot;Mostly clear&quot; &quot;Cloudy&quot; ... #&gt; .. ..$ cloud_base_m : int [1:161] 600 600 600 3300 3300 2610 2500 1110 1110 2340 ... #&gt; .. ..$ cloud_oktas : int [1:161] 1 1 1 8 8 3 8 1 1 3 ... #&gt; .. ..$ cloud_type_id : int [1:161] 6 6 6 NA NA NA 35 6 6 NA ... #&gt; .. ..$ cloud_type : chr [1:161] &quot;Stratocumulus&quot; &quot;Stratocumulus&quot; &quot;Stratocumulus&quot; &quot;-&quot; ... #&gt; .. ..$ delta_t : num [1:161] 4.5 4 3.2 2.7 2.8 3.3 3.6 7.5 7.4 7.7 ... #&gt; .. ..$ gust_kmh : int [1:161] 33 33 39 39 37 52 52 59 50 59 ... #&gt; .. ..$ gust_kt : int [1:161] 18 18 21 21 20 28 28 32 27 32 ... #&gt; .. ..$ air_temp : num [1:161] 21.7 20.4 19.4 18.5 18.6 19.3 19.5 23.1 24.2 25 ... #&gt; .. ..$ dewpt : num [1:161] 14 13.5 13.9 13.8 13.7 13.6 13.2 9.3 11.1 11.5 ... #&gt; .. ..$ press : num [1:161] 1005 1006 1005 1004 1004 ... #&gt; .. ..$ press_qnh : num [1:161] 1006 1006 1005 1005 1005 ... #&gt; .. ..$ press_msl : num [1:161] 1005 1006 1005 1004 1004 ... #&gt; .. ..$ press_tend : chr [1:161] &quot;-&quot; &quot;-&quot; &quot;-&quot; &quot;-&quot; ... #&gt; .. ..$ rain_trace : chr [1:161] &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... #&gt; .. ..$ rel_hum : int [1:161] 61 64 70 74 73 69 67 41 43 42 ... #&gt; .. ..$ sea_state : chr [1:161] &quot;-&quot; &quot;-&quot; &quot;-&quot; &quot;-&quot; ... #&gt; .. ..$ swell_dir_worded : chr [1:161] &quot;-&quot; &quot;-&quot; &quot;-&quot; &quot;-&quot; ... #&gt; .. ..$ swell_height : logi [1:161] NA NA NA NA NA NA ... #&gt; .. ..$ swell_period : logi [1:161] NA NA NA NA NA NA ... #&gt; .. ..$ vis_km : chr [1:161] &quot;10&quot; &quot;10&quot; &quot;10&quot; &quot;10&quot; ... #&gt; .. ..$ weather : chr [1:161] &quot;-&quot; &quot;-&quot; &quot;-&quot; &quot;Showers&quot; ... #&gt; .. ..$ wind_dir : chr [1:161] &quot;N&quot; &quot;NNW&quot; &quot;N&quot; &quot;NNE&quot; ... #&gt; .. ..$ wind_spd_kmh : int [1:161] 22 22 28 30 30 33 35 39 37 32 ... #&gt; .. ..$ wind_spd_kt : int [1:161] 12 12 15 16 16 18 19 21 20 17 ... JSON data is often hierarchically structured or nested in this way, and you’ll need to work your way through the structure to get to the data you need. class(bom_data) #&gt; [1] &quot;list&quot; names(bom_data) #&gt; [1] &quot;observations&quot; names(bom_data$observations) #&gt; [1] &quot;notice&quot; &quot;header&quot; &quot;data&quot; class(bom_data$observations$data) #&gt; [1] &quot;data.frame&quot; bom_data$observations$data %&gt;% as_tibble() #&gt; # A tibble: 161 x 35 #&gt; sort_order wmo name history_product local_date_time local_date_time… #&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 0 94866 Melb… IDV60901 01/02:00pm 20201201140000 #&gt; 2 1 94866 Melb… IDV60901 01/01:30pm 20201201133000 #&gt; 3 2 94866 Melb… IDV60901 01/01:00pm 20201201130000 #&gt; 4 3 94866 Melb… IDV60901 01/12:30pm 20201201123000 #&gt; 5 4 94866 Melb… IDV60901 01/12:27pm 20201201122700 #&gt; 6 5 94866 Melb… IDV60901 01/12:03pm 20201201120300 #&gt; 7 6 94866 Melb… IDV60901 01/12:00pm 20201201120000 #&gt; 8 7 94866 Melb… IDV60901 01/11:37am 20201201113700 #&gt; 9 8 94866 Melb… IDV60901 01/11:30am 20201201113000 #&gt; 10 9 94866 Melb… IDV60901 01/11:14am 20201201111400 #&gt; # … with 151 more rows, and 29 more variables: aifstime_utc &lt;chr&gt;, lat &lt;dbl&gt;, #&gt; # lon &lt;dbl&gt;, apparent_t &lt;dbl&gt;, cloud &lt;chr&gt;, cloud_base_m &lt;int&gt;, #&gt; # cloud_oktas &lt;int&gt;, cloud_type_id &lt;int&gt;, cloud_type &lt;chr&gt;, delta_t &lt;dbl&gt;, #&gt; # gust_kmh &lt;int&gt;, gust_kt &lt;int&gt;, air_temp &lt;dbl&gt;, dewpt &lt;dbl&gt;, press &lt;dbl&gt;, #&gt; # press_qnh &lt;dbl&gt;, press_msl &lt;dbl&gt;, press_tend &lt;chr&gt;, rain_trace &lt;chr&gt;, #&gt; # rel_hum &lt;int&gt;, sea_state &lt;chr&gt;, swell_dir_worded &lt;chr&gt;, swell_height &lt;lgl&gt;, #&gt; # swell_period &lt;lgl&gt;, vis_km &lt;chr&gt;, weather &lt;chr&gt;, wind_dir &lt;chr&gt;, #&gt; # wind_spd_kmh &lt;int&gt;, wind_spd_kt &lt;int&gt; Just for fun, here’s the temperature as a line graph. library(ggplot2) bom_data$observations$data %&gt;% ggplot(aes(x = lubridate::as_datetime(local_date_time_full), y = apparent_t)) + geom_line() + theme_minimal() + theme(legend.position = &quot;bottom&quot;, axis.title = element_blank(), legend.title = element_blank()) + labs(title = &quot;Melbourne Airport, Apparent Temperature (celsius)&quot;, caption = &quot;Source: Bureau of Meteorology&quot;) "],["xml-data.html", "5.3 XML data", " 5.3 XML data The XML standard has been in general use since 1998, but it isn’t used for serving web resources anywhere near as widely as it once was. Nevertheless, occasionally you’ll come across web resources or other data in XML format. Navigating XML data structures can be a bit hairy and is worthy of a workshop of its own. We recommend the xml2 package for working with XML, which can also load data directly from URLs using the read_xml() function. The example below loads data from the Queensland Government’s Air Quality Monitoring Live data feed. airqual_xml &lt;- xml2::read_xml(&quot;https://apps.des.qld.gov.au/air-quality/xml/feed.php?category=1&amp;region=ALL&quot;) airqual_xml #&gt; {xml_document} #&gt; &lt;airdata provider=&quot;Department of Environment and Science&quot; state=&quot;Queensland&quot; country=&quot;Australia&quot;&gt; #&gt; [1] &lt;category name=&quot;Air Quality&quot; measurementhour=&quot;12&quot; measurementdate=&quot;2020-1 ... "],["working-with-web-requests.html", "5.4 Working with web requests", " 5.4 Working with web requests Sometimes it’s necessary to work with web requests on a lower level, to do fancier things like setting cookies, building more complex web requests or using authentication. The httr packages provides relatively easy functionality for making more complex web requests. A full explanation of httr is out of our scope (see the httr quickstart guide for a more thorough introduction), but a simple example below shows how we could access the BoM JSON data using our own web request. bom_url &lt;- &quot;http://www.bom.gov.au/fwo/IDV60901/IDV60901.94866.json&quot; response &lt;- httr::GET(bom_url) response #&gt; Response [http://www.bom.gov.au/fwo/IDV60901/IDV60901.94866.json] #&gt; Date: 2020-12-01 03:15 #&gt; Status: 200 #&gt; Content-Type: application/json #&gt; Size: 142 kB #&gt; { #&gt; &quot;observations&quot;: { #&gt; &quot;notice&quot;: [ #&gt; { #&gt; &quot;copyright&quot;: &quot;Copyright Commonwealth of Australia 2020, Bureau of Meteoro... #&gt; &quot;copyright_url&quot;: &quot;http://www.bom.gov.au/other/copyright.shtml&quot;, #&gt; &quot;disclaimer_url&quot;: &quot;http://www.bom.gov.au/other/disclaimer.shtml&quot;, #&gt; &quot;feedback_url&quot;: &quot;http://www.bom.gov.au/other/feedback&quot; #&gt; } #&gt; ], #&gt; ... bom_json &lt;- httr::content(response, as = &quot;text&quot;) #&gt; No encoding supplied: defaulting to UTF-8. substr(bom_json, 1, 1000) #&gt; [1] &quot;{\\n\\t\\&quot;observations\\&quot;: {\\n\\t\\t\\&quot;notice\\&quot;: [\\n\\t\\t\\t{\\n\\t\\t\\t\\t\\&quot;copyright\\&quot;: \\&quot;Copyright Commonwealth of Australia 2020, Bureau of Meteorology. For more information see: http://www.bom.gov.au/other/copyright.shtml http://www.bom.gov.au/other/disclaimer.shtml\\&quot;,\\n\\t\\t\\t\\t\\&quot;copyright_url\\&quot;: \\&quot;http://www.bom.gov.au/other/copyright.shtml\\&quot;,\\n\\t\\t\\t\\t\\&quot;disclaimer_url\\&quot;: \\&quot;http://www.bom.gov.au/other/disclaimer.shtml\\&quot;,\\n\\t\\t\\t\\t\\&quot;feedback_url\\&quot;: \\&quot;http://www.bom.gov.au/other/feedback\\&quot;\\n\\t\\t\\t}\\n\\t\\t],\\n\\t\\t\\&quot;header\\&quot;: [\\n\\t\\t\\t{\\n\\t\\t\\t\\t\\&quot;refresh_message\\&quot;: \\&quot;Issued at 2:11 pm EDT Tuesday 1 December 2020\\&quot;,\\n\\t\\t\\t\\t\\&quot;ID\\&quot;: \\&quot;IDV60901\\&quot;,\\n\\t\\t\\t\\t\\&quot;main_ID\\&quot;: \\&quot;IDV60900\\&quot;,\\n\\t\\t\\t\\t\\&quot;name\\&quot;: \\&quot;Melbourne Airport\\&quot;,\\n\\t\\t\\t\\t\\&quot;state_time_zone\\&quot;: \\&quot;VIC\\&quot;,\\n\\t\\t\\t\\t\\&quot;time_zone\\&quot;: \\&quot;EDT\\&quot;,\\n\\t\\t\\t\\t\\&quot;product_name\\&quot;: \\&quot;Capital City Observations\\&quot;,\\n\\t\\t\\t\\t\\&quot;state\\&quot;: \\&quot;Victoria\\&quot;\\n\\t\\t\\t}\\n\\t\\t],\\n\\t\\t\\&quot;data\\&quot;: [\\n\\t\\t\\t{\\n\\t\\t\\t\\t\\&quot;sort_order\\&quot;: 0,\\n\\t\\t\\t\\t\\&quot;wmo\\&quot;: 94866,\\n\\t\\t\\t\\t\\&quot;name\\&quot;: \\&quot;Melbourne Airport\\&quot;,\\n\\t\\t\\t\\t\\&quot;history_product\\&quot;: \\&quot;IDV60901\\&quot;,\\n\\t\\t\\t\\t\\&quot;local_date_time\\&quot;: \\&quot;01/02:00pm\\&quot;,\\n\\t\\t\\t\\t\\&quot;local_date_time_full\\&quot;: \\&quot;20201201140000\\&quot;,\\n\\t\\t\\t\\t\\&quot;aifstime_utc\\&quot;: \\&quot;2020120103000&quot; cat(substr(bom_json, 1, 1000)) #&gt; { #&gt; &quot;observations&quot;: { #&gt; &quot;notice&quot;: [ #&gt; { #&gt; &quot;copyright&quot;: &quot;Copyright Commonwealth of Australia 2020, Bureau of Meteorology. For more information see: http://www.bom.gov.au/other/copyright.shtml http://www.bom.gov.au/other/disclaimer.shtml&quot;, #&gt; &quot;copyright_url&quot;: &quot;http://www.bom.gov.au/other/copyright.shtml&quot;, #&gt; &quot;disclaimer_url&quot;: &quot;http://www.bom.gov.au/other/disclaimer.shtml&quot;, #&gt; &quot;feedback_url&quot;: &quot;http://www.bom.gov.au/other/feedback&quot; #&gt; } #&gt; ], #&gt; &quot;header&quot;: [ #&gt; { #&gt; &quot;refresh_message&quot;: &quot;Issued at 2:11 pm EDT Tuesday 1 December 2020&quot;, #&gt; &quot;ID&quot;: &quot;IDV60901&quot;, #&gt; &quot;main_ID&quot;: &quot;IDV60900&quot;, #&gt; &quot;name&quot;: &quot;Melbourne Airport&quot;, #&gt; &quot;state_time_zone&quot;: &quot;VIC&quot;, #&gt; &quot;time_zone&quot;: &quot;EDT&quot;, #&gt; &quot;product_name&quot;: &quot;Capital City Observations&quot;, #&gt; &quot;state&quot;: &quot;Victoria&quot; #&gt; } #&gt; ], #&gt; &quot;data&quot;: [ #&gt; { #&gt; &quot;sort_order&quot;: 0, #&gt; &quot;wmo&quot;: 94866, #&gt; &quot;name&quot;: &quot;Melbourne Airport&quot;, #&gt; &quot;history_product&quot;: &quot;IDV60901&quot;, #&gt; &quot;local_date_time&quot;: &quot;01/02:00pm&quot;, #&gt; &quot;local_date_time_full&quot;: &quot;20201201140000&quot;, #&gt; &quot;aifstime_utc&quot;: &quot;2020120103000 bom_data &lt;- jsonlite::fromJSON(bom_json) str(bom_data) #&gt; List of 1 #&gt; $ observations:List of 3 #&gt; ..$ notice:&#39;data.frame&#39;: 1 obs. of 4 variables: #&gt; .. ..$ copyright : chr &quot;Copyright Commonwealth of Australia 2020, Bureau of Meteorology. For more information see: http://www.bom.gov.a&quot;| __truncated__ #&gt; .. ..$ copyright_url : chr &quot;http://www.bom.gov.au/other/copyright.shtml&quot; #&gt; .. ..$ disclaimer_url: chr &quot;http://www.bom.gov.au/other/disclaimer.shtml&quot; #&gt; .. ..$ feedback_url : chr &quot;http://www.bom.gov.au/other/feedback&quot; #&gt; ..$ header:&#39;data.frame&#39;: 1 obs. of 8 variables: #&gt; .. ..$ refresh_message: chr &quot;Issued at 2:11 pm EDT Tuesday 1 December 2020&quot; #&gt; .. ..$ ID : chr &quot;IDV60901&quot; #&gt; .. ..$ main_ID : chr &quot;IDV60900&quot; #&gt; .. ..$ name : chr &quot;Melbourne Airport&quot; #&gt; .. ..$ state_time_zone: chr &quot;VIC&quot; #&gt; .. ..$ time_zone : chr &quot;EDT&quot; #&gt; .. ..$ product_name : chr &quot;Capital City Observations&quot; #&gt; .. ..$ state : chr &quot;Victoria&quot; #&gt; ..$ data :&#39;data.frame&#39;: 161 obs. of 35 variables: #&gt; .. ..$ sort_order : int [1:161] 0 1 2 3 4 5 6 7 8 9 ... #&gt; .. ..$ wmo : int [1:161] 94866 94866 94866 94866 94866 94866 94866 94866 94866 94866 ... #&gt; .. ..$ name : chr [1:161] &quot;Melbourne Airport&quot; &quot;Melbourne Airport&quot; &quot;Melbourne Airport&quot; &quot;Melbourne Airport&quot; ... #&gt; .. ..$ history_product : chr [1:161] &quot;IDV60901&quot; &quot;IDV60901&quot; &quot;IDV60901&quot; &quot;IDV60901&quot; ... #&gt; .. ..$ local_date_time : chr [1:161] &quot;01/02:00pm&quot; &quot;01/01:30pm&quot; &quot;01/01:00pm&quot; &quot;01/12:30pm&quot; ... #&gt; .. ..$ local_date_time_full: chr [1:161] &quot;20201201140000&quot; &quot;20201201133000&quot; &quot;20201201130000&quot; &quot;20201201123000&quot; ... #&gt; .. ..$ aifstime_utc : chr [1:161] &quot;20201201030000&quot; &quot;20201201023000&quot; &quot;20201201020000&quot; &quot;20201201013000&quot; ... #&gt; .. ..$ lat : num [1:161] -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 -37.7 ... #&gt; .. ..$ lon : num [1:161] 145 145 145 145 145 ... #&gt; .. ..$ apparent_t : num [1:161] 18.8 17.3 15.3 14 14.1 14.2 13.9 15.6 17.5 19.4 ... #&gt; .. ..$ cloud : chr [1:161] &quot;Mostly clear&quot; &quot;Mostly clear&quot; &quot;Mostly clear&quot; &quot;Cloudy&quot; ... #&gt; .. ..$ cloud_base_m : int [1:161] 600 600 600 3300 3300 2610 2500 1110 1110 2340 ... #&gt; .. ..$ cloud_oktas : int [1:161] 1 1 1 8 8 3 8 1 1 3 ... #&gt; .. ..$ cloud_type_id : int [1:161] 6 6 6 NA NA NA 35 6 6 NA ... #&gt; .. ..$ cloud_type : chr [1:161] &quot;Stratocumulus&quot; &quot;Stratocumulus&quot; &quot;Stratocumulus&quot; &quot;-&quot; ... #&gt; .. ..$ delta_t : num [1:161] 4.5 4 3.2 2.7 2.8 3.3 3.6 7.5 7.4 7.7 ... #&gt; .. ..$ gust_kmh : int [1:161] 33 33 39 39 37 52 52 59 50 59 ... #&gt; .. ..$ gust_kt : int [1:161] 18 18 21 21 20 28 28 32 27 32 ... #&gt; .. ..$ air_temp : num [1:161] 21.7 20.4 19.4 18.5 18.6 19.3 19.5 23.1 24.2 25 ... #&gt; .. ..$ dewpt : num [1:161] 14 13.5 13.9 13.8 13.7 13.6 13.2 9.3 11.1 11.5 ... #&gt; .. ..$ press : num [1:161] 1005 1006 1005 1004 1004 ... #&gt; .. ..$ press_qnh : num [1:161] 1006 1006 1005 1005 1005 ... #&gt; .. ..$ press_msl : num [1:161] 1005 1006 1005 1004 1004 ... #&gt; .. ..$ press_tend : chr [1:161] &quot;-&quot; &quot;-&quot; &quot;-&quot; &quot;-&quot; ... #&gt; .. ..$ rain_trace : chr [1:161] &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; &quot;0.0&quot; ... #&gt; .. ..$ rel_hum : int [1:161] 61 64 70 74 73 69 67 41 43 42 ... #&gt; .. ..$ sea_state : chr [1:161] &quot;-&quot; &quot;-&quot; &quot;-&quot; &quot;-&quot; ... #&gt; .. ..$ swell_dir_worded : chr [1:161] &quot;-&quot; &quot;-&quot; &quot;-&quot; &quot;-&quot; ... #&gt; .. ..$ swell_height : logi [1:161] NA NA NA NA NA NA ... #&gt; .. ..$ swell_period : logi [1:161] NA NA NA NA NA NA ... #&gt; .. ..$ vis_km : chr [1:161] &quot;10&quot; &quot;10&quot; &quot;10&quot; &quot;10&quot; ... #&gt; .. ..$ weather : chr [1:161] &quot;-&quot; &quot;-&quot; &quot;-&quot; &quot;Showers&quot; ... #&gt; .. ..$ wind_dir : chr [1:161] &quot;N&quot; &quot;NNW&quot; &quot;N&quot; &quot;NNE&quot; ... #&gt; .. ..$ wind_spd_kmh : int [1:161] 22 22 28 30 30 33 35 39 37 32 ... #&gt; .. ..$ wind_spd_kt : int [1:161] 12 12 15 16 16 18 19 21 20 17 ... "],["downloading-files.html", "5.5 Downloading files", " 5.5 Downloading files When all else fails, or files are in a format that can’t be parsed directly by an existing R package, downloading files is simple using base R. The GSS datasets we’re using are retrieved when building this book using the base R download and unzip methods. # Download datasets download.file(&quot;http://gss.norc.org/Documents/spss/2018_spss.zip&quot;, &quot;data/gss_2018_spss.zip&quot;) download.file(&quot;http://gss.norc.org/Documents/stata/2018_stata.zip&quot;, &quot;data/gss_2018_stata.zip&quot;) # Unzip unzip(&quot;data/gss_2018_spss.zip&quot;, exdir = &quot;data/gss&quot;) unzip(&quot;data/gss_2018_stata.zip&quot;, exdir = &quot;data/gss&quot;) If you need to authenticate yourself, or to construct a more complex web request, httr is always a safe bet. "],["official-statistics.html", "6 Official statistics", " 6 Official statistics Traditionally official statistics and government released data has been accessed from the agency’s website via awkwardly structured Excel sheets and dense zip files. With the growth of the open data movement, much more government data is publicly available, and a good starting point for Australian data is the various state and territory data..gov.au websites (although try finding anything on the national data.gov.au website, I dare you!). There are a growing number of R packages for easily and directly accessing official statistics data, although coverage of Australian data sources is limited. A good resource for official statistics is the Awesome official statistics software list. readabs A very special mention goes to the readabs package, created and maintained by Matt Cowgill from the Grattan Institute. readabs is amazingly useful, but the ABS data holdings are large and it can take a bit of getting used to. A good starting point is the introductory vignette. The example below presents birth and death rates from 1981 to 2020, using data loaded directly from the read_abs() function. library(readabs) # Load ABS National, state and territory population estimate # https://www.abs.gov.au/statistics/people/population/national-state-and-territory-population/latest-release pop &lt;- read_abs(&quot;3101.0&quot;, tables = 1) #&gt; Finding filenames for tables corresponding to ABS catalogue 3101.0 #&gt; Attempting to download files from catalogue 3101.0, National, state and territory population #&gt; Extracting data from downloaded spreadsheets #&gt; Tidying data from imported ABS spreadsheets pop #&gt; # A tibble: 2,028 x 12 #&gt; table_no sheet_no table_title date series value series_type data_type #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 310101 Data1 TABLE 1. P… 1981-06-01 Birth… 60.3 Original FLOW #&gt; 2 310101 Data1 TABLE 1. P… 1981-06-01 Death… 26.7 Original FLOW #&gt; 3 310101 Data1 TABLE 1. P… 1981-06-01 Natur… 33.6 Original FLOW #&gt; 4 310101 Data1 TABLE 1. P… 1981-06-01 Inter… 78 Original FLOW #&gt; 5 310101 Data1 TABLE 1. P… 1981-06-01 Inter… 78 Original FLOW #&gt; 6 310101 Data1 TABLE 1. P… 1981-06-01 Overs… 48.2 Original FLOW #&gt; 7 310101 Data1 TABLE 1. P… 1981-06-01 Overs… 19.1 Original FLOW #&gt; 8 310101 Data1 TABLE 1. P… 1981-06-01 Net P… 29.1 Original FLOW #&gt; 9 310101 Data1 TABLE 1. P… 1981-06-01 Migra… -3.6 Original FLOW #&gt; 10 310101 Data1 TABLE 1. P… 1981-06-01 Net O… 25.6 Original FLOW #&gt; # … with 2,018 more rows, and 4 more variables: collection_month &lt;chr&gt;, #&gt; # frequency &lt;chr&gt;, series_id &lt;chr&gt;, unit &lt;chr&gt; pop &lt;- pop %&gt;% separate_series() #&gt; Warning in separate_series(.): value column(s) have NA values. library(ggplot2) pop %&gt;% filter(series_1 %in% c(&quot;Births&quot;, &quot;Deaths&quot;)) %&gt;% mutate(value = value * 1000) %&gt;% ggplot(aes(x = date, y = value, col = series_1)) + geom_line() + theme_minimal() + theme(legend.position = &quot;bottom&quot;, axis.title = element_blank(), legend.title = element_blank()) + labs(title = &quot;Australia, Births and Deaths, 1981-2020&quot;, caption = &quot;Source: ABS 3101.0&quot;) "]]
